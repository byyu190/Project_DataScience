---
title: "projek"
author: "Bayu Tirta Aji & Hanif Muhammad Rizqi"
date: "1/11/2021"
output: html_document
runtime: shiny

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r rlib}
library(tm) #membersihkan data
library(vroom) #load dataset
library(here) #menyimpan dataset
```
## Cleaning Dataset
```{r load dataset}
datanya <- vroom(here('Restaurant_Reviews.csv'))
komen <- datanya$Review
komenc  <- Corpus(VectorSource(komen))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
reviewclean <- tm_map(komenc, removeURL)
removeNL <- function(y) gsub("\n", " ", y)
reviewclean <- tm_map(reviewclean, removeNL)
replacecomma <- function(y) gsub(",", "", y)
reviewclean <- tm_map(reviewclean, replacecomma)
removeRT <- function(y) gsub("RT ", "", y)
reviewclean <- tm_map(reviewclean, removeRT)
removetitik2 <- function(y) gsub(":", "", y)
reviewclean <- tm_map(reviewclean, removetitik2)
removetitikkoma <- function(y) gsub(";", " ", y)
reviewclean <- tm_map(reviewclean, removetitikkoma)
removetitik3 <- function(y) gsub("p…", "", y)
reviewclean <- tm_map(reviewclean, removetitik3)
removeamp <- function(y) gsub("&amp;", "", y)
reviewclean <- tm_map(reviewclean, removeamp)
removeUN <- function(z) gsub("@\\w+", "", z)
reviewclean <- tm_map(reviewclean, removeUN)
remove.all <- function(xy) gsub("[^[:alpha:][:space:]]*", "", xy)
reviewclean <- tm_map(reviewclean,remove.all)
reviewclean <- tm_map(reviewclean, removePunctuation)
reviewclean <- tm_map(reviewclean, tolower)
myStopwords = readLines("stopwords-en.txt")
reviewclean <- tm_map(reviewclean,removeWords,myStopwords)

dataframe<-data.frame(text=unlist(sapply(reviewclean, `[`)), stringsAsFactors=F)

write.csv(dataframe,file = 'clean.csv')
```


## Bagan/Scarletplot
```{r bagi data}
library(e1071) #naive bayes
library(caret) #klasifikasi data
library(syuzhet) #fungsi get_nrc_sentiment
#digunakan untuk membaca file csv yang sudah di cleaning data 
restauran<-read.csv("clean.csv",stringsAsFactors = FALSE)
#digunakan untuk mengeset variabel cloumn text menjadi char
review <-as.character(restauran$text)
#Calls the NRC sentiment dictionary to calculate the presence of eight different emotions and their corresponding valence in a text file.
s<-get_nrc_sentiment(review)

review_combine<-cbind(restauran$text)
par(mar=rep(3,4))
a<- barplot(colSums(s),col=rainbow(10),ylab='count',main='sentiment analisis')
bagan <- a
```
##NAIVE BAYES
```{r naivebayes}
#library untuk penggunaan corpus dalam cleaning data
library(tm)
library(RTextTools)
#library yang terdapat sebuah algoritma naivebayes
library(e1071)
library(dplyr)
library(caret)

# Load dataset
my_Dataset <- read.csv("Restaurant_Reviews.csv", stringsAsFactors = FALSE)

glimpse(my_Dataset)

# Ambil kolom reviewnya dan Liked (classnya)
restaurant_review <- my_Dataset %>%
  select(text = Review, class = Liked)

restaurant_review$class <- as.factor(restaurant_review$class)

glimpse(restaurant_review)

# Ambil 1000 baris per class data untuk sample
like_review <- restaurant_review %>%
  filter(class == "1") 


dislike_review <- restaurant_review %>%
  filter(class == "0") 


restaurant_review <- rbind(like_review, dislike_review)

restaurant_review %>% count(class)


# Acak data set biar ga beurutan
set.seed(10)
restaurant_review <- restaurant_review[sample(nrow(restaurant_review)), ]

## CLEANING DATASET

# Mengubah data reviewnya ke bentuk corpus
corpus <- Corpus(VectorSource(restaurant_review$text))

# Cleaning
corpus_clean <- corpus %>%
  tm_map(content_transformer(tolower)) %>% 
  tm_map(removePunctuation) %>%
  tm_map(removeNumbers) %>%
  tm_map(removeWords, stopwords(kind="en")) %>%
  tm_map(stripWhitespace)

corpus[[15]]$content
corpus_clean[[15]]$content

# Mengubah corpus jadi dtm
dtm <- DocumentTermMatrix(corpus_clean)

# Partisi 3:1 data untuk test dan training
restaurant_review_train <- restaurant_review[1:700,]
restaurant_review_test <- restaurant_review[701:1000,]

corpus_clean_train <- corpus_clean[1:700]
corpus_clean_test <- corpus_clean[701:1000]

dtm_train <- dtm[1:701,]
dtm_test <- dtm[701:1000,]

dim(dtm_train)
dim(dtm_test)


# Feature Selection, ambil kata yang muncul minimal 5 kali
fiveFreq <- findFreqTerms(dtm_train, 5)

length(fiveFreq)

# set directory tempat simpan feature yg digunakan
# save featurenya
saveRDS(fiveFreq, "features.rds")


# Sesuaikan fitur pada data train dan test dengan fitur yang sudah diseleksi sebelumnya
dtm_train_nb <- corpus_clean_train %>%
  DocumentTermMatrix(control=list(dictionary = fiveFreq))

dtm_test_nb <- corpus_clean_test %>%
  DocumentTermMatrix(control=list(dictionary = fiveFreq))

dim(dtm_train_nb)
dim(dtm_test_nb)

# Funsi untuk convert jumlah kemunculan kata jadi yes (ada) dan no (ga ada)
convert_count <- function(x) {
  y <- ifelse(x > 0, 1,0)
  y <- factor(y, levels=c(0,1), labels=c("No", "Yes"))
  y
}

# Apply the convert_count function to get final training and testing DTMs
trainNB <- apply(dtm_train_nb, 2, convert_count)
testNB <- apply(dtm_test_nb, 2, convert_count)

view(testNB)

# Membuat model naive bayes dari data training
classifier <- naiveBayes(trainNB, restaurant_review_train$class, laplace = 1)

# set directory tempat simpan model naivebayes nya
# save model untuk di gunakan pada aplikasi
save(classifier , file = 'NaiveBayesClassifier.rda')


# test model naivebayes nya
pred <- predict(classifier, newdata=testNB)

# Buat table hasil prediksi
table("Predictions"= pred,  "Actual" = restaurant_review_test$class)

# Confusion Matrix
conf_mat <- confusionMatrix(pred, restaurant_review_test$class)
conf_mat$overall['Accuracy']
```

## Wordcloud
```{r bagi data2}
#library untuk penggunaan corpus dalam cleaning data
library(tm)
library(RTextTools)
#library yang terdapat sebuah algoritma naivebayes
library(e1071)
library(dplyr)
library(caret)
df<-read.csv("clean.csv",stringsAsFactors = FALSE)
glimpse(df)

#Set the seed of R‘s random number generator, which is useful for creating simulations or random objects that can be reproduced.
set.seed(20)
df<-df[sample(nrow(df)),]
df<-df[sample(nrow(df)),]
glimpse(df)

corpus<-Corpus(VectorSource(df$text))
corpus
inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan 
corpus.clean<-corpus%>%
    tm_map(content_transformer(tolower))%>%
    tm_map(removePunctuation)%>%
    tm_map(removeNumbers)%>%
    tm_map(removeWords,stopwords(kind="en"))%>%
    tm_map(stripWhitespace)
dtm<-DocumentTermMatrix(corpus.clean)

inspect(dtm[1:10,1:20])

df.train<-df[1:50,]
df.test<-df[51:100,]

dtm.train<-dtm[1:50,]
dtm.test<-dtm[51:100,]

corpus.clean.train<-corpus.clean[1:50]
corpus.clean.test<-corpus.clean[51:100]

dim(dtm.train)
fivefreq<-findFreqTerms(dtm.train,5)
length(fivefreq)

dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))

#dim(dtm.train.nb)

dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))

dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)


library(wordcloud)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))

```


## Shiny
```{r global}
library(shiny)
library(here)
library(vroom)
library(dplyr)
library(ggplot2)
library(plotly)
library(syuzhet)
library(DT)

twitter<- vroom(here("Restaurant_Reviews.csv"))
twitterr <- twitter %>% mutate(Liked = ifelse(Liked == "1", "yes", "no"))


tweet<- twitterr$text
  
  
ui <- fluidPage(
    titlePanel("Analisa"),
        mainPanel(
            
            tabsetPanel(type = "tabs",
                        tabPanel("Bagan", plotOutput("scatterplot")), 
                        # Plot
                        tabPanel("Data", DT::dataTableOutput('tbl')), 
                        # Output Data Dalam Tabel
                        tabPanel("Wordcloud", plotOutput("Wordcloud"))
                        )
        )
    )




# SERVER
server <- function(input, output) {
    

  
    # Output Data
    output$tbl = DT::renderDataTable({
        DT::datatable(twitterr, options = list(lengthChange = FALSE))
    })
    
    #Output Bagan
    output$scatterplot <-     renderPlot({produk_dataset<-read.csv("clean.csv",stringsAsFactors = FALSE)

    review <-as.character(produk_dataset$text)
    
    get_nrc_sentiment('happy')
    get_nrc_sentiment('excitement')
    s<-get_nrc_sentiment(review)
    
    review_combine<-cbind(produk_dataset$text,s)
    par(mar=rep(3,4))
    barplot(colSums(s),col=rainbow(10),ylab='count',main='sentiment analisis')
      }, height=400)
    
    #Output Wordcloud
    output$Wordcloud <- renderPlot({
    set.seed(20)
    df<-df[sample(nrow(df)),]
    df<-df[sample(nrow(df)),]
    glimpse(df)

    corpus<-Corpus(VectorSource(df$text))
    corpus
    inspect(corpus[1:10])
#fungsinya untuk membersihkan data data yang tidak dibutuhkan 
    corpus.clean<-corpus%>%
        tm_map(content_transformer(tolower))%>%
        tm_map(removePunctuation)%>%
        tm_map(removeNumbers)%>%
        tm_map(removeWords,stopwords(kind="en"))%>%
        tm_map(stripWhitespace)
    dtm<-DocumentTermMatrix(corpus.clean)

    inspect(dtm[1:10,1:20])
    
    df.train<-df[1:50,]
    df.test<-df[51:100,]
    
    dtm.train<-dtm[1:50,]
    dtm.test<-dtm[51:100,]
    
    corpus.clean.train<-corpus.clean[1:50]
    corpus.clean.test<-corpus.clean[51:100]
    
    dim(dtm.train)
    fivefreq<-findFreqTerms(dtm.train,5)
    length(fivefreq)
    
    dtm.train.nb<-DocumentTermMatrix(corpus.clean.train,control = list(dictionary=fivefreq))

#dim(dtm.train.nb)

dtm.test.nb<-DocumentTermMatrix(corpus.clean.test,control = list(dictionary=fivefreq))

dim(dtm.test.nb)
 
convert_count <- function(x){
    y<-ifelse(x>0,1,0)
    y<-factor(y,levels=c(0,1),labels=c("no","yes"))
    y
}
trainNB<-apply(dtm.train.nb,2,convert_count)
testNB<-apply(dtm.test.nb,1,convert_count)


library(wordcloud)
wordcloud(corpus.clean,min.freq = 4,max.words=100,random.order=F,colors=brewer.pal(8,"Dark2"))
  })
}
shinyApp(ui = ui, server = server)
```
